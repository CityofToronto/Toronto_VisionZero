{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\n# The dataset changed a little in _r1: \"acctime\" used to be all 0:00:00. \n# In the revised csv `acctime` is converted to integer. \n# There's probably a number of entries that fall beyond 2359 (and possibly a few negative ones as well), so we'll have to clean those. \ndf0 = pd.read_csv(\"../input/toronto-collisions-dataset-r1/involved2020_forinsight_r1.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df0 is a mix of two datasets: \"Collisions-Events\" and \"Collisions-Involved\"\ndf0.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df0.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df0.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This shows the number of collisions itself (NOT the number of people involved in the collisions)\ndf0['collision_no'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create df1 from df0\ndf1 = df0.copy()\n\n# Add new column 'acc_date'\ndf1['acc_date'] = pd.to_datetime(df0['accdate'], errors = 'raise')\ndf1['year'] = df1['acc_date'].dt.year\ndf1['month_name'] = df1['acc_date'].dt.month_name()\ndf1['day_name'] = df1['acc_date'].dt.day_name()\n\n# Drop columns 'accdate' and 'accyear'\ndf1.drop(['accdate', 'accyear'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['acc_date'].dt.year.unique() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['involved_injury_class'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('{:,}'.format(df1['involved_injury_class'].isna().sum()), \n      'data points in \"involved_injury_class\" are nan, which will be removed.')\ndf1.dropna(subset=['involved_injury_class'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['involved_class'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('{:,}'.format(df1['involved_class'].isna().sum()), \n      'data points in \"involved_class\" are nan, which will be removed.')\ndf1.dropna(subset=['involved_class'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('{:,}'.format(df1['longitude'].isna().sum()), \n      'data points in \"longitude\" are nan, which will be removed.')\ndf1.dropna(subset=['longitude'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['latitude'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop points whose lon-lat are not in Toronto (spatial outlier)\n# Toronto lon-lat ranges:\n# longitude: (-79.65 , -79.08)\n# latitude: (43.57 , 43.85)\n\ni = df1[(df1['longitude']<-79.65) | (df1['longitude']>-79.08) | (df1['latitude']<43.57) | (df1['latitude']>43.85)].index\ndf1.drop(i, inplace=True)\n\nprint('There were {:,} spatial outliers which are removed now.'.format(i.size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add new columns to df1\ndf1['# involved'] = int(1)\n\ndf1['# injured'] = int(0)\ndf1.loc[df1['involved_injury_class'].isin(['MINIMAL', 'MINOR', 'MAJOR']), ['# injured']] = int(1) \n\ndf1['# fatalities'] = int(0)\ndf1.loc[df1['involved_injury_class']=='FATAL', ['# fatalities']] = int(1) \n\ndf1['# KSI'] = int(0)\ndf1.loc[df1['involved_injury_class'].isin(['MAJOR', 'FATAL']), ['# KSI']] = int(1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create dfE: the dataframe of \"Collisions-Events\" from df1\n\n# We don't include the following columns which are related to \"Collisions-Involved\" except 'involved_class' and involved_injury_class': \n#                                     'traffic_control', 'vehicle_no', 'vehicle_class', 'initial_dir', 'impact_type', 'safety_equip_used', \n#                                     'driver_action','driver_condition', \n#                                     'pedestrian_action', 'pedestrian_condition', 'pedestrian_collision_type', \n#                                     'cyclist_action', 'cyclist_condition', 'cyclist_collision_type', \n#                                     'manoeuver', 'posted_speed', 'actual_speed'.\n\n# Also we don't iclude the following columns which are not going to be useful for our analysis although they belong to \"Collisions-Events\":\n#                                     'stname1', 'streetype1', 'dir1', 'stname2', 'streetype2', 'dir2', 'stname3', 'streetype3', 'dir3'.\n\ndfE = df1.groupby(['collision_no', 'acc_date', 'year', 'month_name', 'day_name', 'acctime', 'longitude','latitude',\n                   'road_class', 'road_surface_cond', 'visibility', 'light']).\\\nagg({'involved_class': ', '.join,\n     'involved_injury_class': ', '.join,\n    '# involved':'sum',\n    '# injured': 'sum',\n    '# fatalities': 'sum',\n    '# KSI': 'sum'})\n\ndfE.reset_index(inplace=True)\ndfE.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"When preparing to share maps or layers on the Web, it is recommended to reproject your source data to the **Web Mercator** coordinate system. Doing so will ensure that your map data is located correctly and aligns properly with other services such as popular content providers Microsoft® Bing™ Maps, Google Maps™, and ESRI® ArcGISSM Online, which have standardized their services on the Web Mercator coordinate system."},{"metadata":{"trusted":true},"cell_type":"code","source":"import datashader as ds\nfrom datashader.utils import lnglat_to_meters\n\n# Project longitude and latitude onto web mercator plane\ndfE.loc[:, 'X'], dfE.loc[:, 'Y'] = lnglat_to_meters(dfE['longitude'], dfE['latitude'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Change the order of columns\ncols = dfE.columns.tolist() \nnew_cols = cols[0:8] + [cols[18]] + [cols[19]] + cols[8:18]\ndfE = dfE.reindex(columns=new_cols)\ndfE.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dfE.to_csv('dfE.csv')\n# It will be exported for the other notebooks: 'Maps', 'HeatMap', 'Graphs'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## After July 2019 minor and non-injury (property damage) collisions are not updated by Collision Reporting Centre (CRC), but we assume that the fatalities and major injuries are updated by Toronto Police Services (TPS) "},{"metadata":{"trusted":true},"cell_type":"markdown","source":"---"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the dataframe of neighborhoods (neighb) in Toronto. It's a shape file(.shp):\nimport geopandas as gpd\nneighb = gpd.read_file(\"../input/neighbourhoods-toronto-2/Neighbourhoods.shp\", encoding=\"utf-8\")\nneighb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# It sounds like both 'FIELD_7' and 'FIELD_8' show the name of the neighborhoos.\n# So check if there is any differences between them: \nall(neighb['FIELD_7']==neighb['FIELD_8'])\n\n# 'FIELD_7' is actually neighborhood NAME and 'FIELD_8' is DESC.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Insight is located in the 'Church-Yonge Corridor (75)' neighborhood\nINSIGHT = neighb.loc[neighb['FIELD_7']=='Church-Yonge Corridor (75)']\nINSIGHT","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INSIGHT.reset_index(drop=True, inplace=True)\nfig, ax = plt.subplots(figsize=(15,15))\nneighb.plot(ax=ax, facecolor='gray')\nINSIGHT.plot(ax=ax, facecolor='red')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The next step is to get the data in the right format. \n# The way we do this is by turning our regular Pandas DataFrame into a geo-DataFrame, which will require us to specify as parameters:\n#    the original DataFrame, \n#    our coordinate reference system (CRS), and \n#    the geometry of our new DataFrame.\n\n# In order to format our geometry appropriately, we will need to convert the longitude and latitude into Points (imported from shapely).\n\nfrom shapely.geometry import Point, Polygon\n\ncrs = {'init': 'epsg:4326'}\n\ngeometry = [Point(xy) for xy in zip(dfE['longitude'], dfE['latitude'])]   # Make sure to always specify the “Longitude” column before the “Latitude” column!\n\ngeo_dfE = gpd.GeoDataFrame(dfE, # specify our data\n                           crs=crs, # specify our coordinate reference system\n                           geometry=geometry) # specify the geometry list we created\ngeo_dfE.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,15))\nneighb.plot(ax=ax, alpha=1, facecolor='gray')\ngeo_dfE[geo_dfE['acc_date'].dt.year==2018].plot(ax=ax, markersize=1, color='blue', marker='o', label='Number of collisions in 2018')\nplt.legend(prop={'size': 15})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Computationally, detecting if a point is inside a polygon is most commonly done using a specific formula called Ray Casting algorithm. Luckily, we do not need to create such a function ourselves for conducting the Point in Polygon (PIP) query. Instead, we can take advantage of Shapely’s binary predicates that can evaluate the topolocical relationships between geographical objects, such as the PIP as we’re interested here.\n\nThere are basically two ways of conducting PIP in Shapely:\n\n    - using a function called .within() that checks if a point is within a polygon\n    - using a function called .contains() that checks if a polygon contains a point\n\nNotice: even though we are talking here about Point in Polygon operation, it is also possible to check if a LineString or Polygon is inside another Polygon."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check which collision points are in INSIGHT neighborhood\npip_mask = geo_dfE.within(INSIGHT.loc[0, 'geometry'])\nprint(pip_mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# geo_dfE['neighborhood'] = \" \"\n\n# # start = time.time()\n\n# for i in range(len(geo_dfE)):\n#     for j in range(len(neighb)):\n#         if geo_dfE.loc[i, 'geometry'].within(neighb.loc[j, 'geometry']):\n#             geo_dfE.loc[i, 'neighborhood'] = neighb.loc[j, 'FIELD_7']\n#             break\n\n# # elapsed = (time.time() - start)\n# # from datetime import timedelta\n# # str(timedelta(seconds=elapsed))\n\n# geo_dfE.head","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip_data = geo_dfE.loc[pip_mask]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INSIGHT.reset_index(drop=True, inplace=True)\nfig, ax = plt.subplots(figsize=(15,15))\nneighb.plot(ax=ax, alpha=0.8, facecolor='gray')\nINSIGHT.plot(ax=ax, facecolor='red')\npip_data.plot(ax=ax, color='blue', markersize=0.001)     # plot also the points on top of the map\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the geo dataframe of INSIGHT ('Church-Yonge Corridor (75)')\ngeo_dfE_I = pip_data\ngeo_dfE_I","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# It will be used for the notebook 'Regression'\n# geo_dfE_I.to_csv('geo_dfE_I.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}